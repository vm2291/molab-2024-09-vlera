\section{Experimental Setup}
\label{sec:experimental-setup}

\subsection{Datasets}
\label{sec:experimental-setup-datasets}

We rely on four different datasets, two for pre-training, one for fine-tuning, and one for linear probing of phonological features.

The first of these is Kinetics400~\cite{carreira2017quo}, the de facto standard dataset of human action videos. It contains 400 categories of human actions, with around 600 hours of video in total. We use it exclusively for self-supervised pre-training, ignoring the labels of the videos.

Additionally, we use OpenASL~\cite{Shi2022OpenASL}, one of the largest and most diverse ASL translation datasets, with 288 hours of ASL videos paired with English text translation and more than 200 signers. Since we only use it for self-supervised pre-training, we use OpenASL videos without their subtitle counterparts.

We fine-tune all of our models using WLASL2000~\cite{Li2020WLASL}. The original version of this dataset consisted of 14 hours of isolated sign language videos in ASL, with 2000 labels in total. However, recent analysis of this dataset~\cite{Dafnis2022Bidirectional} revealed major weaknesses and inconsistencies that are a product of relying on English translations as sign names. For this reason, we use the manually-corrected version of WLASL2000~\cite{neidle2022alternative}, with only 1535 labels based on ASL glosses instead of English translations and 12 hours of video.

For our linear probing experiments, we draw from sign language phonology, that is, the study of abstract grammatical components that are combined into meaningful utterances~\cite{brentari2019sign}. We extend the gloss-based WLASL2000 labels with phonological features extracted from ASL-LEX 2.0~\cite{sehyr2021asllex}. Due to inconsistent labeling across datasets and dialect variations, we only map a subset of 916 WLASL labels with their corresponding features where an unambiguous correspondence can be found. That is, we strip the morpheme translation part of each gloss label from both WLASL2000 and ASL-LEX 2.0, and only map one to another when there is a unique exact match. This is partially inspired by previous work~\cite{tavella2022wlasl,kezar2023improving}, with two key differences. First, we rely on manually labeled glosses instead of treating the original WLASL2000 labels as gloss approximations, and second, we do not use these additional features as a weak supervision signal, but as a tool help us characterize our self-supervised models.

For a detailed description of each phonological feature used in this study, see Table~\ref{tab:phono-features-description}. Note that the number of classes in Table~\ref{tab:phono-features-description} might be smaller than the original ASL-LEX 2.0 labels, as a product of unambiguous data available in WLASL2000. Additionally, Table~\ref{tab:phono-categorization} groups the phonological features we extract from ASL-LEX 2.0 into broad categories according to the aspect they describe.

\begin{table*}[]
\centering
\begin{tabular}{llc}
\hline
\textbf{Feature} & \textbf{Description} & \textbf{Classes} \\
\hline
Sign Type & Describes whether a sign is one-handed or two-handed and its symmetry properties. & 6 \\
Major Location & General location of the dominant hand in relation to the body. & 5 \\
First Minor Location & Subdivisions within each minor location except ``neutral'' location. & 35 \\
Second Minor Location & Used when the dominant hand moves while signing. & 30 \\
Contact & Describes whether the dominant hand touches the major location during signing. & 2 \\
Handshape & Shape of the dominant signing hand. & 49 \\
Non-Dom. Handshape & Shape of the non-dominant hand. & 45 \\
Selected Fingers & Describes combinations of finger movement and position in the dominant hand. & 10 \\
Flexion & Describes selected finger positions at morpheme onset. & 8 \\
Thumb Position & Describes whether the thumb is in contact with other fingers in the dominant hand. & 2 \\
Path Movement & Path followed by the dominant hand. & 8 \\
Wrist Twist & Describes whether ulnar rotation is present in a sign's movement. & 2 \\
Repeated Movement & Describes whether a sign involves movement repetition of any kind. & 2 \\
\hline
\end{tabular}
\caption{Description of all phonological features used in this study.}
\label{tab:phono-features-description}
\end{table*}

\begin{table}[]
\centering
\begin{tabular}{ll}
\hline
\textbf{Main Category} & \textbf{Features} \\
\hline
Sign Type & Sign Type \\
\hline
Location & Major Location, Minor Location, \\
  &Second Minor Location, Contact \\
\hline
Hand Configuration & Thumb Position, Flexion, \\
  &Handshape, Selected Fingers, \\
    & Non-dominant Handshape \\
\hline
Movement & Path Movement, Wrist Twist, \\
  & Repeated Movement \\
\hline
\end{tabular}
\caption{Broad cateogrization of phonological features included in this study.}
\label{tab:phono-categorization}
\end{table}

\subsection{Pre-Training}
\label{sec:experimental-setup-pretraining}

For each of our four models, we explore four pre-training configurations. The first is to pre-train each model in Kinetics400 using the pre-training setup and hyperparameters from the model's original paper. The second is to keep the setup and hyperparameters, but replace Kinetics400 with OpenASL. Our third configuration is to first pre-train the model on Kinetics400 as in the corresponding paper, and add a second pre-training stage on OpenASL, with all the hyperparameters staying the same except learning rate, which we instead reduce to a tenth of the original. Last, our fourth configuration is to pre-train a model on the union of Kinetics400 and OpenASL, keeping each model's original pre-training setup and hyperparameters.


\subsection{Evaluation}
\label{sec:experimental-setup-evaluation}

To evaluate our models, we conduct fine-tuning and layer-wise linear probing. We fine-tune on the gloss-based version of WLASL2000, and compare models by top-1 accuracy. For linear probing, we freeze the model and train softmax classifiers with the output of each layer as input, as an attempt to measure whether phonological features are encoded well in our trained models. We do so before and after fine-tuning on WLASL2000. This is inspired by previous work that analyzes linguistic properties of speech models~\cite{pasad2021layer,ji2022predicting,pasad2023comparative}. We select the models to analyze based on ISLR fine-tuning performance.
